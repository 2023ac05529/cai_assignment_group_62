{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 15.0,
  "eval_steps": 500,
  "global_step": 195,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 12.563883781433105,
      "learning_rate": 9.794871794871795e-05,
      "loss": 43.4,
      "step": 5
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 12.610166549682617,
      "learning_rate": 9.53846153846154e-05,
      "loss": 41.0375,
      "step": 10
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 14.561230659484863,
      "learning_rate": 9.282051282051283e-05,
      "loss": 40.9937,
      "step": 15
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 12.406965255737305,
      "learning_rate": 9.025641025641026e-05,
      "loss": 38.2687,
      "step": 20
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 14.580403327941895,
      "learning_rate": 8.76923076923077e-05,
      "loss": 37.6063,
      "step": 25
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 12.295188903808594,
      "learning_rate": 8.512820512820513e-05,
      "loss": 36.0812,
      "step": 30
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 12.823922157287598,
      "learning_rate": 8.256410256410256e-05,
      "loss": 35.1625,
      "step": 35
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 10.220515251159668,
      "learning_rate": 8e-05,
      "loss": 32.6875,
      "step": 40
    },
    {
      "epoch": 3.4615384615384617,
      "grad_norm": 12.757905960083008,
      "learning_rate": 7.743589743589744e-05,
      "loss": 31.6844,
      "step": 45
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 11.80207633972168,
      "learning_rate": 7.487179487179487e-05,
      "loss": 29.7781,
      "step": 50
    },
    {
      "epoch": 4.230769230769231,
      "grad_norm": 14.946454048156738,
      "learning_rate": 7.23076923076923e-05,
      "loss": 29.9438,
      "step": 55
    },
    {
      "epoch": 4.615384615384615,
      "grad_norm": 8.835601806640625,
      "learning_rate": 6.974358974358974e-05,
      "loss": 27.8188,
      "step": 60
    },
    {
      "epoch": 5.0,
      "grad_norm": 14.921731948852539,
      "learning_rate": 6.717948717948718e-05,
      "loss": 25.9625,
      "step": 65
    },
    {
      "epoch": 5.384615384615385,
      "grad_norm": 9.200566291809082,
      "learning_rate": 6.461538461538462e-05,
      "loss": 25.1781,
      "step": 70
    },
    {
      "epoch": 5.769230769230769,
      "grad_norm": 9.011459350585938,
      "learning_rate": 6.205128205128206e-05,
      "loss": 25.0562,
      "step": 75
    },
    {
      "epoch": 6.153846153846154,
      "grad_norm": 11.069528579711914,
      "learning_rate": 5.948717948717949e-05,
      "loss": 23.9094,
      "step": 80
    },
    {
      "epoch": 6.538461538461538,
      "grad_norm": 9.2412109375,
      "learning_rate": 5.692307692307692e-05,
      "loss": 22.7563,
      "step": 85
    },
    {
      "epoch": 6.923076923076923,
      "grad_norm": 10.358142852783203,
      "learning_rate": 5.435897435897436e-05,
      "loss": 21.1938,
      "step": 90
    },
    {
      "epoch": 7.3076923076923075,
      "grad_norm": 10.798124313354492,
      "learning_rate": 5.17948717948718e-05,
      "loss": 20.4937,
      "step": 95
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 10.200937271118164,
      "learning_rate": 4.923076923076924e-05,
      "loss": 19.7312,
      "step": 100
    },
    {
      "epoch": 8.076923076923077,
      "grad_norm": 11.04749870300293,
      "learning_rate": 4.666666666666667e-05,
      "loss": 18.175,
      "step": 105
    },
    {
      "epoch": 8.461538461538462,
      "grad_norm": 11.442684173583984,
      "learning_rate": 4.4102564102564104e-05,
      "loss": 17.4375,
      "step": 110
    },
    {
      "epoch": 8.846153846153847,
      "grad_norm": 12.701157569885254,
      "learning_rate": 4.1538461538461544e-05,
      "loss": 16.9187,
      "step": 115
    },
    {
      "epoch": 9.23076923076923,
      "grad_norm": 12.771240234375,
      "learning_rate": 3.8974358974358976e-05,
      "loss": 15.3547,
      "step": 120
    },
    {
      "epoch": 9.615384615384615,
      "grad_norm": 14.156434059143066,
      "learning_rate": 3.641025641025641e-05,
      "loss": 14.4812,
      "step": 125
    },
    {
      "epoch": 10.0,
      "grad_norm": 25.775840759277344,
      "learning_rate": 3.384615384615385e-05,
      "loss": 14.6406,
      "step": 130
    },
    {
      "epoch": 10.384615384615385,
      "grad_norm": 15.796716690063477,
      "learning_rate": 3.128205128205128e-05,
      "loss": 12.9594,
      "step": 135
    },
    {
      "epoch": 10.76923076923077,
      "grad_norm": 14.42267894744873,
      "learning_rate": 2.8717948717948717e-05,
      "loss": 11.8812,
      "step": 140
    },
    {
      "epoch": 11.153846153846153,
      "grad_norm": 15.663664817810059,
      "learning_rate": 2.6153846153846157e-05,
      "loss": 10.3219,
      "step": 145
    },
    {
      "epoch": 11.538461538461538,
      "grad_norm": 14.666378021240234,
      "learning_rate": 2.358974358974359e-05,
      "loss": 9.3313,
      "step": 150
    },
    {
      "epoch": 11.923076923076923,
      "grad_norm": 15.024152755737305,
      "learning_rate": 2.102564102564103e-05,
      "loss": 10.1969,
      "step": 155
    },
    {
      "epoch": 12.307692307692308,
      "grad_norm": 13.720491409301758,
      "learning_rate": 1.8461538461538465e-05,
      "loss": 8.7906,
      "step": 160
    },
    {
      "epoch": 12.692307692307692,
      "grad_norm": 11.17286205291748,
      "learning_rate": 1.5897435897435897e-05,
      "loss": 8.7828,
      "step": 165
    },
    {
      "epoch": 13.076923076923077,
      "grad_norm": 13.4815034866333,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 8.882,
      "step": 170
    },
    {
      "epoch": 13.461538461538462,
      "grad_norm": 15.189362525939941,
      "learning_rate": 1.0769230769230771e-05,
      "loss": 8.1,
      "step": 175
    },
    {
      "epoch": 13.846153846153847,
      "grad_norm": 15.749338150024414,
      "learning_rate": 8.205128205128205e-06,
      "loss": 7.6367,
      "step": 180
    },
    {
      "epoch": 14.23076923076923,
      "grad_norm": 9.108294486999512,
      "learning_rate": 5.641025641025641e-06,
      "loss": 7.7461,
      "step": 185
    },
    {
      "epoch": 14.615384615384615,
      "grad_norm": 10.145687103271484,
      "learning_rate": 3.0769230769230774e-06,
      "loss": 7.6234,
      "step": 190
    },
    {
      "epoch": 15.0,
      "grad_norm": 9.692299842834473,
      "learning_rate": 5.128205128205128e-07,
      "loss": 7.1453,
      "step": 195
    }
  ],
  "logging_steps": 5,
  "max_steps": 195,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 507291980267520.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
